{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concept of collaborative Filtering, predictions (filtering) about the interests of a user by collecting preferences or taste information from many users (collaborating).\n",
    "\n",
    "![alt text](https://upload.wikimedia.org/wikipedia/commons/thumb/5/52/Collaborative_filtering.gif/300px-Collaborative_filtering.gif)\n",
    "\n",
    "In this lab, we'll implement __knn__ for finding the nearest neighbors and predict rating for each project and user by using \"sklern\". We separate this lab to 3 parts\n",
    "- Data Preparation\n",
    "- Fiting Model\n",
    "- Prediction to recommend next projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# basic library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'coding/data/'\n",
    "df = pd.read_csv(path+'userLog_201801_201802_for_participants.csv', delimiter = ';', error_bad_lines = False, low_memory = False)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 100\n",
    "sample_users = set(df['userCode'].sample(n=10000, random_state=random_state))\n",
    "sample_data = df[df['userCode'].isin(sample_users)]\n",
    "sample_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sample_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Data Cleaning and Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create visited datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data['datetime'] = sample_data.apply(lambda row : datetime.datetime(row['year'], row['month'], row['day'], row['hour']), axis=1)\n",
    "sample_data['date'] = sample_data['datetime'].map(lambda x : x.date())\n",
    "sample_data['yearmonth'] = sample_data['date'].map(lambda x: str(x.year) +'-'+ str(x.month).zfill(2))\n",
    "sample_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clean data ex. cut outllier, filter users & projects which have less transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_interacted = 30\n",
    "project_count = sample_data.groupby(['project_id']).size()\n",
    "ignore_project = set(project_count[project_count > min_interacted].index)\n",
    "print(len(ignore_project))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filter = sample_data[~sample_data['project_id'].isin(ignore_project)]\n",
    "df_filter.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filter = <FILL IN>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Split training-testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def SplitTrainTest(df, date):\n",
    "    \n",
    "    df['interacted'] = 1\n",
    "    df_train = df[df.date <  date]\n",
    "    df_test = df[df.date >=  date].sort_values(by = ['userCode', 'datetime'])\n",
    "    \n",
    "    # projects which are in training datasets\n",
    "    project_train = set(df_train['project_id'].values)\n",
    "    df_test = df_test[df_test['project_id'].isin(project_train)]\n",
    "    \n",
    "    # users which are in training datasets\n",
    "    user_train = set(df_train['userCode'].values)\n",
    "    df_test = df_test[df_test['userCode'].isin(user_train)]\n",
    "    \n",
    "    print('# of train dataset:', len(df_train))\n",
    "    print('# of test dataset:', len(df_test))\n",
    "\n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_ = datetime.date(2018, 2, 20)\n",
    "df_train, df_test_full = SplitTrainTest(df_filter, date = date_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_indexed = df_test_full[['userCode', 'project_id', 'interacted', 'flag1Prj']].drop_duplicates().set_index('userCode')\n",
    "df_test_indexed.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "In this part, we'll create users-items matrix for calculating similarity between users. Users-items matrix can be created by many format, in this lab, we'll create 3 matrix :\n",
    "- 0/1 matrix\n",
    "- rating matrix\n",
    "- rating + user profile matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Case 1: 0/1 matrix\n",
    "This part we'll prepare interacted data to identify interacted projects for each users. We need data like below format.\n",
    "```\n",
    "|------------+---+---+---+----+---|\n",
    "| project_id | 1 | 2 | 3 | .. | j |\n",
    "| userCode   |   |   |   |    |   |\n",
    "|------------+---+---+---+----+---|\n",
    "| user A     | 1 | 0 | 0 | .. | 1 |\n",
    "| user B     | 0 | 1 | 0 | .. | 1 |\n",
    "| user C     | 0 | 0 | 1 | .. | 0 |\n",
    "|  ..        | . | . | . | .. | . |\n",
    "|------------+---+---+---+----+---|\n",
    "\n",
    "```\n",
    "\n",
    "- 1 means user interacted that project\n",
    "- 0 means user didn't interact that project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_indexed = df_train[['userCode', 'project_id', 'interacted']].drop_duplicates()\n",
    "df_train_pivot = (df_train_indexed.pivot(index = 'userCode', columns = 'project_id', values = 'interacted')\n",
    "                                  .fillna(0))\n",
    "df_train_pivot.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform users-items to matrix for model and set index of df_train for fast search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_matrix = df_train_pivot.values\n",
    "df_train_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_indexed = df_train_indexed.set_index('userCode')\n",
    "df_train_indexed.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Case 2: Rating matrix\n",
    "Define rating by number of interactions with each project and scale them by bining (look at the distribution of data and define boundary)\n",
    "\n",
    "ex. (0-1]   ==> rating = 1\n",
    "\n",
    "    (1-2]   ==> rating = 2\n",
    "    \n",
    "    (2-4]   ==> rating = 3\n",
    "    \n",
    "    (4-7]   ==> rating = 4\n",
    "    \n",
    "    (7-inf] ==> rating = 5\n",
    "\n",
    "```\n",
    "|------------+---+---+---+----+---|\n",
    "| project_id | 1 | 2 | 3 | .. | j |\n",
    "| userCode   |   |   |   |    |   |\n",
    "|------------+---+---+---+----+---|\n",
    "| user A     | 4 | 0 | 0 | .. | 2 |\n",
    "| user B     | 0 | 3 | 0 | .. | 1 |\n",
    "| user C     | 0 | 0 | 5 | .. | 0 |\n",
    "|  ..        | . | . | . | .. | . |\n",
    "|------------+---+---+---+----+---|\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "------------------------------------------------------------------------------------------\n",
    "\n",
    "#### ! TO DO: prepare rating user-item matrix like above *************************************\n",
    "------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# count number of interaction groupby userCode and project_id\n",
    "df_train_rating = <FILL IN>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# distribution of number of interactions\n",
    "df_train_rating.groupby(['userCode', 'project_id']).size().reset_index()[[0]].boxplot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train_rating['rating'] = <FILL IN>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train_rating_pivot = (df_train_rating.pivot(index = <FILL IN>\n",
    "                                             ,columns = <FILL IN>\n",
    "                                             ,values = <FILL IN>)\n",
    "                                       .fillna(0))\n",
    "df_train_rating_pivot.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train_rating_matrix = <FILL IN>\n",
    "print(df_train_rating_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train_rating_index = df_train_rating.<FILL IN>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Case 3: Rating + user profile matrix\n",
    "Using above rating matrix and concat with user profile ex. weekday etc.\n",
    "\n",
    "```\n",
    "|------------+---+---+---+----+---+-----+-----+-----+-----+-----+-----+-----|\n",
    "| project_id | 1 | 2 | 3 | .. | j | Mon | Tue | Wed | Thu | Fri | Sat | Sun |\n",
    "| userCode   |   |   |   |    |   |     |     |     |     |     |     |     |\n",
    "|------------+---+---+---+----+---|-----+-----+-----+-----+-----+-----+-----+\n",
    "| user A     | 4 | 0 | 0 | .. | 2 | 0.1 | 0.3 | 0.2 | 0.0 | 0.0 | 0.1 | 0.3 |\n",
    "| user B     | 0 | 3 | 0 | .. | 1 | 0.2 | 0.2 | 0.1 | 0.1 | 0.1 | 0.3 | 0.0 |\n",
    "| user C     | 0 | 0 | 5 | .. | 0 | 0.0 | 0.1 | 0.1 | 0.0 | 0.0 | 0.5 | 0.3 |\n",
    "|  ..        | . | . | . | .. | . | ... | ... | ... | ... | ... | ... | ... |\n",
    "|------------+---+---+---+----+--------+-----+-----+-----+-----+-----+------|\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['weekday'] = df_train['datetime'].dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# proportion of #interactions by time interval\n",
    "weekday = df_train.groupby(['userCode', 'weekday']).size()\n",
    "weekday = weekday.groupby(level = 0).apply(lambda x: round(x/float(x.sum()), 2)).reset_index()\n",
    "weekday.columns.values[2] = 0\n",
    "user_weekday = weekday.pivot(index = 'userCode', columns = 'weekday', values = 0).fillna(0).reset_index()\n",
    "user_weekday.columns =  list(user_weekday.columns.values[:1]) + ['day' + str(col) for col in user_weekday.columns.values[1:]]\n",
    "user_weekday.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------\n",
    "\n",
    "#### ! TO DO: **\n",
    "- create other user profile\n",
    "- merge user profile and user rating\n",
    "- create matrix \n",
    "\n",
    "------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "<FILL IN: CREATE USER PROFILE>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_userprofile = pd.merge(df_train_pivot.reset_index()\n",
    "                                , user_weekday\n",
    "                                , how='left'\n",
    "                                , on=['userCode'])\n",
    "df_train_userprofile.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set \"userCode\" to be index for fast search and create matrix user-item matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train_userprofile_indexed = <FILL IN>\n",
    "df_train_userprofile_matrix = <FILL IN>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing KNN for recommender system\n",
    "In this part, we'll use sklearn for knn algorithm. For more infomation, http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Fitting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# library for knn\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------\n",
    "#### ! TO DO: Using NearestNeighbors in sklearn to fit our data **\n",
    "\n",
    "For more infomation, http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\n",
    "\n",
    "------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_neighbors = <FILL IN: define number of nearest neighbor>\n",
    "metric = <FILL IN: define matric for calculating similarity>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = NearestNeighbors(metric = metric\n",
    "                        , algorithm = 'brute'\n",
    "                        ,  n_neighbors = n_neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.fit(df_train_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Finding k nearest neighbors by index and get their rating of each project\n",
    "- __Input:__ user_id\n",
    "- __Output:__ distance and indices of k nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_id = '0383072a-6827-1246-6490-39fc4d46bcd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_train_pivot[df_train_pivot.index == user_id].iloc[0].values.reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "distances, indices = knn.kneighbors(df_train_pivot[df_train_pivot.index == user_id].iloc[0].values.reshape(1, -1)\n",
    "                                     , n_neighbors = n_neighbors)\n",
    "print('distance:', distances)\n",
    "print('indices:', indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get interacted values of k nearest neighbors by indices and calculate rating for each project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_rating_matrix = df_train_matrix[indices,]\n",
    "k_rating_matrix.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_rating = sum(k_rating_matrix)\n",
    "k_weight_rating = sum(k_rating)/n_neighbors\n",
    "print(k_weight_rating)\n",
    "print(k_weight_rating.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------\n",
    "__! TO DO: Calculate \"k_weight_rating\" by using distance to weight rating **__\n",
    "\n",
    "k_weight_rating = sum(k_rating*(1/distance))/sum(1/distance)\n",
    "\n",
    "------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k_weight_rating = <FILL IN>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transform to dataframe with columns 'project_id' and 'k_weight_rating'\n",
    "\n",
    "__! TO DO: Create dataframe \"recommend_df\" which sort values by 'k_weight_rating' and show only topn projects. **__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# topn = <FILL IN>\n",
    "recommend_df = (pd.DataFrame({\"project_id\": df_train_pivot.columns\n",
    "                             ,\"k_weight_rating\": <FILL IN>})\n",
    "                             .<FILL IN>\n",
    "                             .<FILL IN>\n",
    "               )\n",
    "recommend_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Items to ignore\n",
    "We'll recommend new items so we need to ignore interacted items before recommend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------\n",
    "__! TO DO: create \"get_item_interacted\" function which return set of interacted items of each user and ignore them in recommend_df**__\n",
    "\n",
    "------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_item_interacted(df, user_id):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    - df = dataframe which collect interacted projects of users\n",
    "    - userId = user id\n",
    "    \n",
    "    Return:\n",
    "    - set of interacted itemsets\n",
    "    \"\"\"\n",
    "    interacted_projects = <FILL IN>\n",
    "    return set(interacted_projects['project_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "items_to_ignore = get_item_interacted(<FILL IN>)\n",
    "items_to_ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topn = <FILL IN>\n",
    "recommend_df = pd.DataFrame({\"project_id\": df_train_pivot.columns\n",
    "                            ,\"k_weight_rating\": <FILL IN>})\n",
    "\n",
    "recommend_df =  (recommend_df[~recommend_df['project_id'].isin(items_to_ignore)]\n",
    "                .<FILL IN>\n",
    "                .<FILL IN>)             \n",
    "recommend_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "We'll use metric __MAP@k__ for evaluate result.\n",
    "\n",
    "Example of calculating MAP@5\n",
    "\n",
    "```\n",
    "|                                        |                   |        Precision       |          Average         |\n",
    "|----------------------------------------+-------------------+------------------------+--------------------------|\n",
    "| Actual rank: [2, 4, 1, 5]              |  [1, 0, 0, 1, 1]  | [1/1, 0, 0, 2/4, 3/5]  | (1 + 2/4 + 3/5)/4 = 0.53 |\n",
    "| Recommended rank: [5, 9, 3, 1, 2]      |                   |                        |                          |\n",
    "|----------------------------------------+-------------------+------------------------+--------------------------|\n",
    "| Actual rank: [9, 6, 1]                 |  [1, 0, 0, 0, 0]  | [1/1, 0, 0, 2/4, 3/5]  | (1/1)/3 = 0.33           |\n",
    "| Recommended rank: [9, 2, 5, 0, 4]      |                   |                        |                          |\n",
    "|----------------------------------------+-------------------+------------------------+--------------------------|\n",
    "| Actual rank: [6, 0, 4]                 |  [0, 0, 0, 1, 1]  | [0, 0, 0, 1/4, 2/5]    | (1/4 + 2/5)/3 = 0.22     |\n",
    "| Recommended rank: [1, 10, 11, 4, 6]    |                   |                        |                          |\n",
    "|----------------------------------------+-------------------+------------------------+--------------------------|\n",
    "```\n",
    "Mean Average Precision @ 5 = (0.53 + 0.33 + 0.22)/3 = 0.36\n",
    "\n",
    "** It's ap for only 1 user. If you would like to evaluate all users, pls. submit file on kaggle :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ap_func(actual_list, recommend_list, k=7):\n",
    "    \n",
    "    m = len(actual_list)\n",
    "    recoms = []\n",
    "    precision = 0\n",
    "    for i, item_ in enumerate(recommend_list):\n",
    "        if item_ in actual_list:\n",
    "            recoms.append(1)\n",
    "            precision += round(sum(recoms[:i+1])/(i+1), 2)\n",
    "        else:\n",
    "            recoms.append(0)\n",
    "          \n",
    "    ap = round(precision/min(m, k), 2)\n",
    "    return ap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_list = <FILL IN>\n",
    "recommend_list = <FILL IN> \n",
    "ap = ap_func(actual_list, recommend_list, 7)\n",
    "print(ap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform data for submit to kaggle\n",
    "\n",
    "Format of dataframe for 'transform_to_kaggle' function, consist of 2 columns\n",
    "- userCode\n",
    "- project_id : order by sequence of recommendation (7 sequences)\n",
    "\n",
    "```\n",
    "|------------+--------------|\n",
    "|  userCode  |  project_id  |\n",
    "|------------+--------------|\n",
    "| user A     |      4       |\n",
    "| user A     |     21       |\n",
    "| user A     |     34       |\n",
    "|  ..        |     ..       |\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_to_kaggle(recommed_df):\n",
    "    \n",
    "    \"\"\"\n",
    "    Input:\n",
    "        - recommed_df: userCode and project_id\n",
    "    \n",
    "    Returns:\n",
    "        - recommed_df: \n",
    "    \"\"\"\n",
    "    testing_dataset = []\n",
    "    recommed_df_indexed = recommed_df.set_index('userCode')\n",
    "    \n",
    "    for idx, user_id in enumerate(list(recommed_df_indexed.index.unique().values)):\n",
    "        \n",
    "        interacted_testset = recommed_df_indexed[recommed_df_indexed.index == user_id]\n",
    "        rank_actual = list(interacted_testset['project_id'].values)\n",
    "\n",
    "        if len(rank_actual) > 0:\n",
    "            rank_actual_str = ' '.join(str(r) for r in rank_actual)\n",
    "            testing_dataset.append({\"userCode\": user_id\n",
    "                                   ,\"project_id\": rank_actual_str})\n",
    "            \n",
    "    testing_df = pd.DataFrame(testing_dataset)\n",
    "    testing_df = testing_df[['userCode', 'project_id']]\n",
    "    return testing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submit_file = transform_to_kaggle(recommend_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
